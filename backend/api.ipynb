{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de89dc66-6090-4db1-86e7-235c3eb4001e",
   "metadata": {},
   "source": [
    "### IMPORTACIONES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbeabfb2-f619-4178-9236-53f3fd81512c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import math\n",
    "from datetime import datetime, timedelta\n",
    "from fastapi import FastAPI, HTTPException\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "from pydantic import BaseModel\n",
    "import yfinance as yf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9e027c-2bcb-4d9d-b212-f441ea98b57f",
   "metadata": {},
   "source": [
    "### CARGAR MODELO ENTRENADO Y SCALER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73bff61c-9fe4-428d-acca-d1128ef270cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = 'trained_model.keras'\n",
    "SCALER_PATH = 'scaler.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3098c6db-3978-43f8-9e19-0a975077e9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f25fe99-39da-4313-aa25-c0862b7ce78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(SCALER_PATH, 'rb') as f:\n",
    "    scaler = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e89c13-d205-49b9-95ba-9aa5412729bb",
   "metadata": {},
   "source": [
    "### FAST-API SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2fb5d067-252a-4a4c-a2ff-f8ce520f49e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = FastAPI(title=\"S&P500 Predictor API\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af193b5d-b4b1-4888-81a3-969b585174b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "app.add_middleware(\n",
    "    CORSMiddleware,\n",
    "    allow_origins=[\"http://localhost:4200\"],  # Solo permite Angular local\n",
    "    allow_credentials=True,\n",
    "    allow_methods=[\"*\"],  # Permitir todos los métodos (GET, POST, etc.)\n",
    "    allow_headers=[\"*\"],  # Permitir todas las cabeceras (headers)\n",
    ")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c20467e-cf88-4877-b819-7852f3dc0f21",
   "metadata": {},
   "source": [
    "### MODELOS PYDANTIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e872329a-576b-41ec-9643-9fb00142f78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DateRangePast(BaseModel):\n",
    "    start_date: str\n",
    "    end_date: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df10f65e-f0d5-415a-83e3-2f54d02d108c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DateRangeFuture(BaseModel):\n",
    "    days: int"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9689ef2d-f601-40fb-8cd8-46ad82d20ea3",
   "metadata": {},
   "source": [
    "### END-POINT 1 -> ALL PRICES HISTORY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3bc0c1a3-ac28-4a41-9423-2b4ee2f83ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data = None \n",
    "\n",
    "@app.get(\"/history\")\n",
    "def get_history():\n",
    "    global historical_data\n",
    "\n",
    "    if historical_data is None:\n",
    "        try:\n",
    "            # Descargar histórico completo\n",
    "            df = yf.download('^GSPC', period='max', auto_adjust=True)\n",
    "\n",
    "            if df.empty:\n",
    "                raise HTTPException(status_code=404, detail=\"No se encontraron datos históricos del S&P 500.\")\n",
    "\n",
    "            # Acceder correctamente a la columna 'Close' con MultiIndex\n",
    "            close_series = df[('Close', '^GSPC')]\n",
    "\n",
    "            # Fechas y valores\n",
    "            dates = close_series.index.strftime('%Y-%m-%d').tolist()\n",
    "            values = close_series.round(2).tolist()\n",
    "\n",
    "            # Guardar en caché\n",
    "            historical_data = {\n",
    "                \"dates\": dates,\n",
    "                \"values\": values,\n",
    "                \"total_points\": len(values),\n",
    "                \"message\": \"Histórico completo del S&P 500 desde inicio hasta hoy.\"\n",
    "            }\n",
    "\n",
    "        except Exception as e:\n",
    "            raise HTTPException(status_code=500, detail=f\"Error al obtener datos históricos: {str(e)}\")\n",
    "\n",
    "    return historical_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0515fff-43ea-4adf-8423-351ba82dd4f0",
   "metadata": {},
   "source": [
    "### END-POINT 2 -> NORMAL PREDICTION FOR THE PAST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4342835-4f71-44a9-8e62-f5df16775b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_prediction_metrics = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73de9e18-2192-4ff9-887d-b087e5f6d652",
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.post(\"/normal_prediction\")\n",
    "def normal_prediction(date_range_past: DateRangePast):\n",
    "    global last_prediction_metrics  # Para actualizar métricas globales\n",
    "\n",
    "    try:\n",
    "        # Calcular fecha extendida (pedimos más datos para generar las primeras ventanas)\n",
    "        start_date_obj = datetime.strptime(date_range_past.start_date, \"%Y-%m-%d\")\n",
    "        extended_start_date = start_date_obj - timedelta(days=90)  # Mejor más de 60 para asegurarse\n",
    "        extended_start_date_str = extended_start_date.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "        # Descargar datos desde fecha extendida\n",
    "        df = yf.download('^GSPC', start=extended_start_date_str, end=date_range_past.end_date, auto_adjust=True)\n",
    "\n",
    "        if df.empty:\n",
    "            raise HTTPException(status_code=404, detail=\"No se encontraron datos para las fechas especificadas.\")\n",
    "\n",
    "        df_closing_prices = df[['Close']]  # Mantener solo la columna 'Close'\n",
    "\n",
    "        # Usar scaler original (entrenado)\n",
    "        data = scaler.transform(df_closing_prices)\n",
    "\n",
    "        # Generar secuencias\n",
    "        X_test, y_real_scaled = [], []\n",
    "        for i in range(60, len(data)):\n",
    "            X_test.append(data[i-60:i, 0])      # Ventana de 60 días\n",
    "            y_real_scaled.append(data[i, 0])    # Valor real para esa secuencia\n",
    "\n",
    "        if not X_test:\n",
    "            raise HTTPException(status_code=400, detail=\"No hay suficientes datos (mínimo 60 días).\")\n",
    "\n",
    "        X_test = np.array(X_test).reshape((len(X_test), 60, 1))\n",
    "\n",
    "        # Hacer predicciones\n",
    "        y_pred_scaled = model.predict(X_test)\n",
    "\n",
    "        # Desescalar predicciones\n",
    "        y_pred = scaler.inverse_transform(y_pred_scaled)\n",
    "        y_real = scaler.inverse_transform(np.array(y_real_scaled).reshape(-1, 1))\n",
    "\n",
    "        # Fechas alineadas con las predicciones (desde la posición 60)\n",
    "        all_dates = df_closing_prices.index[60:].strftime('%Y-%m-%d').tolist()\n",
    "\n",
    "        # Filtrar las fechas y predicciones a partir de la fecha real solicitada (start_date)\n",
    "        start_index = next((i for i, date in enumerate(all_dates) if date >= date_range_past.start_date), None)\n",
    "        final_dates = all_dates[start_index:]\n",
    "        final_predictions = y_pred.flatten().tolist()[start_index:]\n",
    "        final_real_values = y_real[start_index:].flatten().tolist()  # Valores reales alineados\n",
    "\n",
    "        # Filtrar también y_real para calcular métricas solo desde start_date\n",
    "        y_real_filtered = y_real[start_index:]\n",
    "        y_pred_filtered = np.array(final_predictions).reshape(-1, 1)  # Asegurarse que esté en formato correcto para métricas\n",
    "\n",
    "        # Calcular métricas desde start_date\n",
    "        rmse = math.sqrt(mean_squared_error(y_real_filtered, y_pred_filtered))\n",
    "        mae = mean_absolute_error(y_real_filtered, y_pred_filtered)\n",
    "        relative_rmse = (rmse / np.mean(y_real_filtered)) * 100\n",
    "\n",
    "        # Guardar métricas para endpoint /metrics\n",
    "        last_prediction_metrics = {\n",
    "            \"Num_samples\": len(X_test),\n",
    "            \"Start_date\": date_range_past.start_date,\n",
    "            \"End_date\": date_range_past.end_date,\n",
    "            \"RMSE\": round(rmse, 4),\n",
    "            \"MAE\": round(mae, 4),\n",
    "            \"Relative_RMSE_%\": round(relative_rmse, 2)\n",
    "        }\n",
    "\n",
    "        return {\n",
    "            \"predictions\": final_predictions,\n",
    "            \"real_values\": final_real_values,\n",
    "            \"dates\": final_dates,\n",
    "            \"message\": f\"Predicciones de S&P500 desde {date_range_past.start_date} hasta {date_range_past.end_date}\"\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=500, detail=str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a6a26b7-0163-434d-af4e-7bc2f755aef7",
   "metadata": {},
   "source": [
    "### END-POINT 3 -> RECURSIVE PREDICTION FOR THE FUTURE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a04e562a-80f5-4734-8091-9e42483206ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(data, time_step):\n",
    "    X_total, y_total = [], []\n",
    "    \n",
    "    for i in range(time_step, len(data)):\n",
    "        X_total.append(data[i-time_step:i, 0])  # Los últimos 60 días\n",
    "        y_total.append(data[i, 0])  # El precio de cierre del día siguiente\n",
    "    \n",
    "    return np.array(X_total), np.array(y_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a8cc4343-3489-41de-a13c-08f8defb3d9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "df = yf.download('^GSPC', period='max', auto_adjust=True)\n",
    "df_closing_prices = df[['Close']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0eaf4e97-9ba0-4df7-b157-990594bb3f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set_scaled = scaler.fit_transform(df_closing_prices)\n",
    "\n",
    "last_days = training_set_scaled[-61:].astype(np.float32)\n",
    "\n",
    "X_test, y_test = create_dataset(last_days, 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6c5b9881-13d9-489d-913f-c617e8becd4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = datetime.today()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "16a4eb51-9a3d-45f1-912e-c4d771512a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_future_dates(num_days: int):\n",
    "    future_dates = [(start_date + timedelta(days=i)).strftime('%Y-%m-%d') for i in range(num_days + 1)]\n",
    "    return future_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c99af265-3c2f-4f55-aa4f-8d3db6ca8445",
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.post(\"/recursive_prediction\")\n",
    "def recursive_prediction(date_range_future: DateRangeFuture):\n",
    "    global last_prediction_metrics  # Para actualizar métricas globales\n",
    "\n",
    "    try:\n",
    "        # Copia de los últimos 60 valores de X_test\n",
    "        X_test_selection = training_set_scaled[-60:].flatten()\n",
    "        \n",
    "        # Lista para almacenar predicciones futuras\n",
    "        future_prediction = []\n",
    "        \n",
    "        # Diferencia entre el último valor real y el anterior (para ajustar tendencia correctamente)\n",
    "        real_trend = training_set_scaled[-1] - training_set_scaled[-2]\n",
    "        \n",
    "        for _ in range(date_range_future.days):  # 20 días financieros ~ 1 mes normal\n",
    "            # Convertir la secuencia a tensor de TensorFlow correctamente\n",
    "            sequence_for_pred_tensor = tf.convert_to_tensor(X_test_selection.reshape(1, 60, 1), dtype=tf.float32)\n",
    "        \n",
    "            # Predecir el siguiente valor\n",
    "            next_day_prediction = model(sequence_for_pred_tensor, training=False).numpy().flatten()[0]\n",
    "        \n",
    "            # Comparar la última predicción con el último valor real\n",
    "            last_real_value = training_set_scaled[-1]\n",
    "            last_predicted_value = future_prediction[-1] if future_prediction else last_real_value\n",
    "        \n",
    "            # Ajuste de tendencia con comparación real\n",
    "            trend_adjustment = (last_real_value - last_predicted_value) * 0.5  # Corrige la desviación en cada iteración\n",
    "            next_day_prediction += np.random.normal(0, 0.005) + trend_adjustment\n",
    "        \n",
    "            # Guardar la predicción\n",
    "            future_prediction.append(next_day_prediction)\n",
    "        \n",
    "            # Actualizar la secuencia para la siguiente iteración\n",
    "            X_test_selection = np.append(X_test_selection[1:], next_day_prediction)\n",
    "\n",
    "        # Transformar predicciones a escala original\n",
    "        prediction_original_scale = scaler.inverse_transform(np.array(future_prediction).reshape(-1, 1))\n",
    "        \n",
    "        # Preparar fechas\n",
    "        end_date = start_date + timedelta(days=date_range_future.days)\n",
    "\n",
    "        return {\n",
    "            \"predictions\": prediction_original_scale.flatten().tolist(),\n",
    "            \"dates\": generate_future_dates(date_range_future.days),\n",
    "            \"message\": f\"Predicciones de S&P500 desde {start_date.strftime('%Y-%m-%d')} hasta {end_date.strftime('%Y-%m-%d')}\"\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=500, detail=str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5de785-9d6f-4d63-b400-b97b6664fbca",
   "metadata": {},
   "source": [
    "### END-POINT 4 -> ERROR METRICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7e4a758a-2e9f-4ec3-92e2-fcf09bc35361",
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.post(\"/metrics\")\n",
    "def get_metrics():\n",
    "    if last_prediction_metrics is None:\n",
    "        raise HTTPException(status_code=404, detail=\"No se ha realizado ninguna predicción aún.\")\n",
    "    return last_prediction_metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
